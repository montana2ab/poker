# R√©sum√© du Fix: Probl√®me avec --num-workers sur Mac M2

## Le Probl√®me que tu as Rencontr√©

Tu lan√ßais l'entra√Ænement avec cette commande :
```bash
python -m holdem.cli.train_blueprint \
    --config configs/blueprint_training_5h.yaml \
    --buckets assets/abstraction/precomputed_buckets.pkl \
    --logdir runs/test \
    --num-workers 4
```

**R√©sultat** : Le moniteur d'activit√© restait plat (pas d'utilisation CPU), l'entra√Ænement ne d√©marrait pas.

Mais quand tu lan√ßais **SANS** `--num-workers` :
```bash
python -m holdem.cli.train_blueprint \
    --config configs/blueprint_training_5h.yaml \
    --buckets assets/abstraction/precomputed_buckets.pkl \
    --logdir runs/test
```

**R√©sultat** : √áa fonctionnait, et tu voyais Python utiliser 2 threads dans le moniteur.

## Pourquoi √ßa Arrivait

Le probl√®me venait de cette ligne dans `parallel_solver.py` :
```python
mp.set_start_method('spawn', force=True)
```

Cette ligne essayait de r√©initialiser le syst√®me de multiprocessing **apr√®s** qu'il ait d√©j√† √©t√© utilis√©, ce qui causait un conflit et emp√™chait les workers de d√©marrer.

## La Solution

J'ai remplac√© l'approche globale par une approche bas√©e sur un contexte :
```python
# Au lieu de :
mp.set_start_method('spawn', force=True)
mp.Queue()
mp.Process()

# Maintenant :
self.mp_context = mp.get_context('spawn')  # Une seule fois dans __init__
self.mp_context.Queue()
self.mp_context.Process()
```

## Comment Tester que √ßa Fonctionne

### Test Rapide (1 minute)
```bash
python -m holdem.cli.train_blueprint \
    --config configs/blueprint_training_5h.yaml \
    --buckets assets/abstraction/precomputed_buckets.pkl \
    --logdir runs/test_fix \
    --time-budget 60 \
    --num-workers 4 \
    --batch-size 100
```

**Ce que tu devrais voir dans le Moniteur d'Activit√© :**
- 1 processus Python principal
- 4 processus Python workers
- Utilisation CPU totale : ~400% (4 cores √† 100% chacun)

### Test Complet (5 heures) avec ton Config Original
```bash
python -m holdem.cli.train_blueprint \
    --config configs/blueprint_training_5h.yaml \
    --buckets assets/abstraction/precomputed_buckets.pkl \
    --logdir runs/5h_4workers \
    --num-workers 4 \
    --batch-size 100
```

### Ou Utilise la Nouvelle Config Optimis√©e
J'ai cr√©√© un nouveau fichier `configs/blueprint_training_5h_parallel.yaml` qui inclut d√©j√† les param√®tres de parall√©lisation :

```bash
python -m holdem.cli.train_blueprint \
    --config configs/blueprint_training_5h_parallel.yaml \
    --buckets assets/abstraction/precomputed_buckets.pkl \
    --logdir runs/5h_parallel
```

## Performance Attendue sur ton Mac M2

| Configuration | Iter/sec | Iterations en 5h | Utilisation CPU |
|--------------|----------|------------------|-----------------|
| **Avant (1 worker)** | ~120-140 | ~2M-2.5M | ~100% (1 core) |
| **Apr√®s (4 workers)** | ~350-500 | ~6M-9M | ~400% (4 cores) |
| **Auto (tous les cores)** | ~600-800 | ~10M-14M | ~800% (8 cores) |

**Sur un Mac M2 standard (8 cores)**, tu devrais obtenir environ **5-8x plus d'it√©rations** dans le m√™me temps !

## Valeurs Recommand√©es pour --num-workers sur M2

- **M2 standard (8 cores)** : `--num-workers 0` (auto) ou `--num-workers 8`
- **M2 Pro (10-12 cores)** : `--num-workers 0` (auto) ou `--num-workers 10-12`
- **M2 Max (12 cores)** : `--num-workers 0` (auto) ou `--num-workers 12`

**Conseil** : Utilise `--num-workers 0` pour laisser le syst√®me d√©tecter automatiquement le nombre de cores.

## Fichiers Modifi√©s

1. **Code Source** (le fix principal) :
   - `src/holdem/mccfr/parallel_solver.py`
   - `src/holdem/realtime/parallel_resolver.py`

2. **Documentation** (pour t'aider) :
   - `FIX_NUM_WORKERS.md` - Documentation compl√®te du fix
   - `TEST_BLUEPRINT_5H.md` - Instructions de test sp√©cifiques
   - `configs/blueprint_training_5h_parallel.yaml` - Config optimis√©e

## V√©rification

Pour v√©rifier que tout fonctionne :

1. ‚úÖ Lance le test rapide (1 minute) ci-dessus
2. ‚úÖ Ouvre le Moniteur d'Activit√©
3. ‚úÖ Cherche les processus "Python"
4. ‚úÖ Tu devrais voir 4-5 processus Python actifs
5. ‚úÖ La somme du % CPU devrait √™tre ~400% ou plus

Si tu vois √ßa, le probl√®me est r√©solu ! üéâ

## Questions Fr√©quentes

**Q: Puis-je encore utiliser mon fichier `blueprint_training_5h.yaml` original ?**  
R: Oui ! Maintenant il fonctionne avec `--num-workers`. Tu peux aussi utiliser le nouveau `blueprint_training_5h_parallel.yaml` qui a les param√®tres de parall√©lisation pr√©-configur√©s.

**Q: Quelle est la meilleure valeur pour --num-workers ?**  
R: Utilise `--num-workers 0` pour auto-d√©tection, ou `--num-workers 4` pour un bon √©quilibre sur M2.

**Q: √áa consomme plus de RAM avec plusieurs workers ?**  
R: Oui, chaque worker utilise de la m√©moire. Sur M2 avec 8-16GB de RAM, 4-8 workers devraient bien fonctionner.

**Q: Et si j'ai d'autres applications ouvertes ?**  
R: Utilise moins de workers (ex: `--num-workers 4` au lieu de 0) pour laisser des ressources aux autres apps.

## Support

Si tu as des questions ou des probl√®mes :
1. V√©rifie les logs dans `runs/[nom_du_run]/`
2. Consulte `FIX_NUM_WORKERS.md` pour plus de d√©tails
3. Consulte `TEST_BLUEPRINT_5H.md` pour des exemples de tests
