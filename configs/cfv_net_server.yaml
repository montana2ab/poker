# CFV Net Configuration for Server (GPU/High-End CPU)
# Larger model for better accuracy on server hardware

# Model architecture
model:
  hidden: [768, 768, 512]  # Larger MLP for server
  dropout: 0.05             # Dropout probability
  quantiles: [0.10, 0.90]   # Prediction quantiles

# Optimizer settings
opt:
  lr: 1.0e-3               # Learning rate
  batch_size: 4096         # Larger batch size for server
  grad_accumulation: 4     # Gradient accumulation (effective: 16k)
  epochs: 30               # More epochs for larger model
  weight_decay: 1.0e-4     # AdamW weight decay (L2)
  grad_clip: 1.0           # Gradient clipping norm

# Learning rate schedule
sched:
  type: cosine             # Cosine annealing
  warmup_frac: 0.05        # Warmup fraction (5% of training)

# Feature settings
features:
  topk_range: 16           # Top-K buckets per player range
  embed_dim: 64            # Bucket embedding dimension

# Loss weights
loss:
  mean_weight: 0.6         # Weight for mean (Huber) loss
  quantile_weight: 0.2     # Weight per quantile (pinball) loss
  huber_delta: 1.0         # Huber loss delta parameter

# Dataset split
split:
  train: 0.96              # Training fraction
  val: 0.02                # Validation fraction
  test: 0.02               # Test fraction

# Early stopping
early_stop:
  metric: mae              # Monitor MAE on validation set
  patience: 5              # More patience for larger model

# Training settings
train:
  seed: 42                 # Random seed
  log_interval: 100        # Log every N batches
  val_interval: 1000       # Validate every N batches
  num_workers: 8           # More workers for server
  pin_memory: true         # Pin memory for faster GPU transfer
  use_amp: true            # Use automatic mixed precision (if GPU)

# Quality thresholds (for validation)
quality:
  max_mae: 0.25            # Stricter MAE for server model
  min_pi_coverage: 0.88    # Higher coverage requirement
  max_ece: 0.04            # Stricter calibration
  max_inference_ms: 5.0    # Server inference budget
